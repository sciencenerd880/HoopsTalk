{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2849b45-5510-4d8d-b582-25edf59861e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a4402a-05f0-4905-a2e9-4539bf931698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Gosar  Paul  Where's Paul? Paul, stand u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you, Paul  Appreciate  Great job you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I knew that she was going  She never stops  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governor, thank you  Martha, go out and win  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We love you  We love you  We love you  We lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>They are fantastic people  Thank you  Look, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>So thank you very much  Thank you, darling  R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>\"5 7 billion, sir \" I said, \"That's a lot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>\" You know what? I was right  We won it  We wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>I mean, that was amazing  No, no, I really do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sequences\n",
       "0     Paul Gosar  Paul  Where's Paul? Paul, stand u...\n",
       "1     Thank you, Paul  Appreciate  Great job you're...\n",
       "2     I knew that she was going  She never stops  S...\n",
       "3     Governor, thank you  Martha, go out and win  ...\n",
       "4     We love you  We love you  We love you  We lov...\n",
       "..                                                 ...\n",
       "181   They are fantastic people  Thank you  Look, t...\n",
       "182   So thank you very much  Thank you, darling  R...\n",
       "183   \"5 7 billion, sir \" I said, \"That's a lot of ...\n",
       "184  \" You know what? I was right  We won it  We wo...\n",
       "185   I mean, that was amazing  No, no, I really do...\n",
       "\n",
       "[186 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/style/trump/df_trump.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ab364b-b2cf-4af5-9964-142c20615d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Think of that  That crazy Nancy  She is crazy  And shifty Schiff'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump.sample()[\"sequences\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89819146-c398-4198-b346-502da4c66fe7",
   "metadata": {},
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "346f259e-d835-4d23-a4b4-3c1ebac93668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2217153-f816-434c-a565-1b5548e77024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', \"\\\"\"))\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = word_tokenize(text.lower().strip())\n",
    "    text = [token.strip() for token in text if token.strip() != \"\"]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "638a4896-25ec-4427-a46b-e5000be51dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72713cbe17cf4565b00c41922a2a3931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Clean_Text\"] = df[\"sequences\"].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae0898e3-8278-4ca9-8e5f-97d4e28924f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [paul, gosar, paul, where, 's, paul, ?, paul, ...\n",
       "1      [thank, you, ,, paul, appreciate, great, job, ...\n",
       "2      [i, knew, that, she, was, going, she, never, s...\n",
       "3      [governor, ,, thank, you, martha, ,, go, out, ...\n",
       "4      [we, love, you, we, love, you, we, love, you, ...\n",
       "                             ...                        \n",
       "181    [they, are, fantastic, people, thank, you, loo...\n",
       "182    [so, thank, you, very, much, thank, you, ,, da...\n",
       "183    [5, 7, billion, ,, sir, i, said, ,, that, 's, ...\n",
       "184    [you, know, what, ?, i, was, right, we, won, i...\n",
       "185    [i, mean, ,, that, was, amazing, no, ,, no, ,,...\n",
       "Name: Clean_Text, Length: 186, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean_Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04458d53-6e58-4750-afa2-acc868c59682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" You know what? I was right  We won it  We won it easily  We won it easily'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[184][\"sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a08ea11-634b-4149-9ccb-07c97bf5a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "counts = Counter()\n",
    "for row in df[\"Clean_Text\"]:\n",
    "    counts.update(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76153b5f-1065-4a98-8845-a63bf4c25729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 561\n",
      "num_words after: 561\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 1\n",
    "\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < MIN_COUNT:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "caf86ee9-bb62-4931-846f-9da60973c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\": 0, \"UNK\": 1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75e3a1ff-2c8b-4705-9a94-7e48837cbce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15c9a029-14a6-410c-9bbc-c69d32ae0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../vocab2index.json', 'w') as f:\n",
    "    json.dump(vocab2index, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b8ae3ff-7d6d-4eac-8fac-dd0a154f39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, max_len=50):\n",
    "    encoded = np.zeros(max_len, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in text])\n",
    "    length = min(max_len, len(enc1)) # if above max len, cut the rest\n",
    "    encoded[:length] = enc1[:length]\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a3bfdd1c-c0e6-4df3-8bec-4b88d0f052d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    186.000000\n",
       "mean      14.865591\n",
       "std        2.803125\n",
       "min        9.000000\n",
       "25%       13.000000\n",
       "50%       15.000000\n",
       "75%       17.000000\n",
       "max       25.000000\n",
       "Name: Clean_Text, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean_Text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "548329c1-fe3e-490d-8e71-5237fc560f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f51438a2fa940e59a2c2014bc5dbc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Clean_Text_Encoded\"] = df[\"Clean_Text\"].progress_apply(lambda x: encode_sentence(x, vocab2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cabb7e89-6e72-479f-b21d-cbfe62adc7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [2, 3, 2, 4, 5, 2, 6, 2, 7, 8, 9, 10, 11, 6, 2...\n",
       "1      [12, 11, 7, 2, 13, 14, 15, 11, 16, 17, 18, 19,...\n",
       "2      [21, 22, 23, 24, 25, 26, 24, 27, 28, 24, 27, 2...\n",
       "3      [32, 7, 12, 11, 33, 7, 34, 35, 36, 37, 34, 35,...\n",
       "4      [40, 41, 11, 40, 41, 11, 40, 41, 11, 40, 41, 1...\n",
       "                             ...                        \n",
       "181    [61, 19, 554, 154, 12, 11, 105, 7, 61, 16, 555...\n",
       "182    [146, 12, 11, 50, 51, 12, 11, 7, 556, 145, 140...\n",
       "183    [130, 272, 131, 7, 469, 21, 188, 7, 23, 5, 46,...\n",
       "184    [11, 90, 85, 6, 21, 25, 139, 40, 279, 49, 40, ...\n",
       "185    [21, 541, 7, 23, 25, 561, 57, 7, 57, 7, 21, 14...\n",
       "Name: Clean_Text_Encoded, Length: 186, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean_Text_Encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17d7d334-62c9-4130-895f-343059eaae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../df_trump_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20751f97-41a8-4182-b04f-de00b2abcde8",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92923a10-73dc-4a1f-8cab-f78cd0ff37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "487f5d74-dfaa-49f0-b925-fc69d96960dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "737679a8-d123-4e9f-8612-767707ccf224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, style_size, pretrained_embeddings=None):\n",
    "        super(StyleEmbeddingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            self.embedding.weight.requires_grad = False  # Optionally, freeze embeddings\n",
    "        self.style_embed = nn.Embedding(2, style_size)  # Assume 2 styles for simplicity\n",
    "        self.rnn = nn.GRU(embed_size + style_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, style):\n",
    "        x = self.embedding(x)\n",
    "        style_embedding = self.style_embed(style).unsqueeze(1).expand_as(x)\n",
    "        x = torch.cat([x, style_embedding], dim=2)\n",
    "        output, _ = self.rnn(x)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94d6ebb0-d145-486d-a729-6f986047db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab2index)\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "style_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c99f8c8-521f-42e8-9618-e27d9f4a2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f42a0fdd-f008-4fe8-9534-cc8bbfdae0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleEmbeddingModel(vocab_size, embed_size, hidden_size, style_size, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed34ce-7b09-4b22-92b1-09564d569f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
