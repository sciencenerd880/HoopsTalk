{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77b4a26-2f62-4407-84f0-47d237cb4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d4fdbb-44e8-4b80-b7b4-e07839ef21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you, thank you  Wow  Wow, and I'm thrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please, let's have a little fun  We got plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You go back … go top-20, top-30  Take a look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And we go back, and we take a look  We want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong-un doesn't know about the problems t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>\" No, Trump is stopping it  Trump is stopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>That's why I say, \"Hey, if they don't like it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>And if you don't support me you're going to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>That had to be a set up  I never saw that guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>Make America great again, but we've done that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sequences\n",
       "0     Thank you, thank you  Wow  Wow, and I'm thrill...\n",
       "1      Please, let's have a little fun  We got plent...\n",
       "2      You go back … go top-20, top-30  Take a look ...\n",
       "3      And we go back, and we take a look  We want t...\n",
       "4      Kim Jong-un doesn't know about the problems t...\n",
       "...                                                 ...\n",
       "1880  \" No, Trump is stopping it  Trump is stopping ...\n",
       "1881   That's why I say, \"Hey, if they don't like it...\n",
       "1882   And if you don't support me you're going to b...\n",
       "1883   That had to be a set up  I never saw that guy...\n",
       "1884   Make America great again, but we've done that...\n",
       "\n",
       "[1885 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump = pd.read_csv(\"../data/style/trump/df_trump.csv\")\n",
    "df_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40dfe47f-0ad3-4a56-bec3-28794958c374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A hundred years ago\\n\\nthere were one and a ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human beings venture into the highest parts of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only 3 percent of the water\\non our planet is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is our planet's final frontier.\\n\\nAn inn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A third of the land\\non our planet is desert.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Both poles of our planet are covered with ice....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vast open plains.\\n\\nImmense spaces.\\n\\nEerie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The coast - the frontier\\nbetween land and sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our planet's continents are fringed\\nby shallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trees.\\n\\nSurely among the most magnificent\\no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Away from all land\\n\\nthe ocean.\\n\\nIt covers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   A hundred years ago\\n\\nthere were one and a ha...\n",
       "1   Human beings venture into the highest parts of...\n",
       "2   Only 3 percent of the water\\non our planet is ...\n",
       "3   This is our planet's final frontier.\\n\\nAn inn...\n",
       "4   A third of the land\\non our planet is desert.\\...\n",
       "5   Both poles of our planet are covered with ice....\n",
       "6   Vast open plains.\\n\\nImmense spaces.\\n\\nEerie ...\n",
       "7   The coast - the frontier\\nbetween land and sea...\n",
       "8   Our planet's continents are fringed\\nby shallo...\n",
       "9   Trees.\\n\\nSurely among the most magnificent\\no...\n",
       "10  Away from all land\\n\\nthe ocean.\\n\\nIt covers ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_david = pd.read_csv(\"../data/style/david/df_david.csv\", encoding=\"ISO-8859-1\")\n",
    "df_david"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6565f49-f945-4a86-a31a-61720e7d1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6128bfc-c367-4f68-a42a-5f325a357ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_david[\"text\"] = df_david[\"text\"].apply(lambda x: re.sub('\\s+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345be584-bfff-44ab-a01e-8b209269c2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A hundred years ago there were one and a half ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human beings venture into the highest parts of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only 3 percent of the water on our planet is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is our planet's final frontier. An inner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A third of the land on our planet is desert. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Both poles of our planet are covered with ice....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vast open plains. Immense spaces. Eerie silenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The coast - the frontier between land and sea....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our planet's continents are fringed by shallow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trees. Surely among the most magnificent of al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Away from all land the ocean. It covers more t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   A hundred years ago there were one and a half ...\n",
       "1   Human beings venture into the highest parts of...\n",
       "2   Only 3 percent of the water on our planet is f...\n",
       "3   This is our planet's final frontier. An inner ...\n",
       "4   A third of the land on our planet is desert. T...\n",
       "5   Both poles of our planet are covered with ice....\n",
       "6   Vast open plains. Immense spaces. Eerie silenc...\n",
       "7   The coast - the frontier between land and sea....\n",
       "8   Our planet's continents are fringed by shallow...\n",
       "9   Trees. Surely among the most magnificent of al...\n",
       "10  Away from all land the ocean. It covers more t..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_david"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2544d2-12f2-46dc-a6f3-e3a8e326c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A hundred years ago there were one and a half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Human beings venture into the highest parts o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Only 3 percent of the water on our planet is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[This is our planet's final frontier,  An inne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A third of the land on our planet is desert, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Both poles of our planet are covered with ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Vast open plains,  Immense spaces,  Eerie sil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[The coast - the frontier between land and sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Our planet's continents are fringed by shallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Trees,  Surely among the most magnificent of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Away from all land the ocean,  It covers more...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   [A hundred years ago there were one and a half...\n",
       "1   [Human beings venture into the highest parts o...\n",
       "2   [Only 3 percent of the water on our planet is ...\n",
       "3   [This is our planet's final frontier,  An inne...\n",
       "4   [A third of the land on our planet is desert, ...\n",
       "5   [Both poles of our planet are covered with ice...\n",
       "6   [Vast open plains,  Immense spaces,  Eerie sil...\n",
       "7   [The coast - the frontier between land and sea...\n",
       "8   [Our planet's continents are fringed by shallo...\n",
       "9   [Trees,  Surely among the most magnificent of ...\n",
       "10  [Away from all land the ocean,  It covers more..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df david split by sentence\n",
    "df_david[\"text\"] = df_david[\"text\"].str.split(\".\")\n",
    "df_david"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8d5ee7-b23d-4d4a-978c-2f4652c0c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_david = df_david.explode(column=\"text\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0217757-47f8-43c3-9bab-9b15d8e0ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A hundred years ago there were one and a half ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now, over six billion crowd our fragile planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But even so, there are still places barely to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This series will take to the last wildernesse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imagine our world without sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>As we explore them, so we gain not only under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>It's not just the future of the whale that to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>We can now destroy, or we can cherish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>The choice is ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2642 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     A hundred years ago there were one and a half ...\n",
       "1        Now, over six billion crowd our fragile planet\n",
       "2      But even so, there are still places barely to...\n",
       "3      This series will take to the last wildernesse...\n",
       "4                         Imagine our world without sun\n",
       "...                                                 ...\n",
       "2637   As we explore them, so we gain not only under...\n",
       "2638   It's not just the future of the whale that to...\n",
       "2639              We can now destroy, or we can cherish\n",
       "2640                                 The choice is ours\n",
       "2641                                                   \n",
       "\n",
       "[2642 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_david"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a2148d-bedc-4d1b-8f99-491ed608a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the sentences that are too long or too short\n",
    "df_david = df_david[(df_david[\"text\"].str.len() >= 50) & (df_david[\"text\"].str.len() <= 150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e440b5-e4db-44f5-ae89-1774a5d4f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trump.rename(columns={\"sequences\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3871b75c-3e25-4f57-a11d-f7172dc36cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you, thank you  Wow  Wow, and I'm thrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please, let's have a little fun  We got plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You go back … go top-20, top-30  Take a look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And we go back, and we take a look  We want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong-un doesn't know about the problems t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>\" No, Trump is stopping it  Trump is stopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>That's why I say, \"Hey, if they don't like it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>And if you don't support me you're going to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>That had to be a set up  I never saw that guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>Make America great again, but we've done that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Thank you, thank you  Wow  Wow, and I'm thrill...\n",
       "1      Please, let's have a little fun  We got plent...\n",
       "2      You go back … go top-20, top-30  Take a look ...\n",
       "3      And we go back, and we take a look  We want t...\n",
       "4      Kim Jong-un doesn't know about the problems t...\n",
       "...                                                 ...\n",
       "1880  \" No, Trump is stopping it  Trump is stopping ...\n",
       "1881   That's why I say, \"Hey, if they don't like it...\n",
       "1882   And if you don't support me you're going to b...\n",
       "1883   That had to be a set up  I never saw that guy...\n",
       "1884   Make America great again, but we've done that...\n",
       "\n",
       "[1885 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c595627-1f20-42bf-bc56-fc7a156fe957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d_/43yhfw3n2wx5mg7dg0cxjld00000gn/T/ipykernel_79766/3286699407.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_david[\"label\"] = 0\n"
     ]
    }
   ],
   "source": [
    "df_trump[\"label\"] = 1\n",
    "df_david[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7e08539a-8656-474e-b5e1-c26280ff415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_david.to_csv(\"../data/style/david/df_david_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e82f1-bedb-40d9-bfe9-c4231690e18a",
   "metadata": {},
   "source": [
    "# combine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46e14d0-e093-4ce7-8c30-d23506bdd376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you, thank you  Wow  Wow, and I'm thrill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please, let's have a little fun  We got plent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You go back … go top-20, top-30  Take a look ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And we go back, and we take a look  We want t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong-un doesn't know about the problems t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>They take many tons of water into their ballo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>Every day, each one swallows some four millio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>Once and not so long ago three hundred thousa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>As we explore them, so we gain not only under...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>It's not just the future of the whale that to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Thank you, thank you  Wow  Wow, and I'm thrill...      1\n",
       "1      Please, let's have a little fun  We got plent...      1\n",
       "2      You go back … go top-20, top-30  Take a look ...      1\n",
       "3      And we go back, and we take a look  We want t...      1\n",
       "4      Kim Jong-un doesn't know about the problems t...      1\n",
       "...                                                 ...    ...\n",
       "3513   They take many tons of water into their ballo...      0\n",
       "3514   Every day, each one swallows some four millio...      0\n",
       "3515   Once and not so long ago three hundred thousa...      0\n",
       "3516   As we explore them, so we gain not only under...      0\n",
       "3517   It's not just the future of the whale that to...      0\n",
       "\n",
       "[3518 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_trump, df_david], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac86213-6ccc-4985-84e1-5945d51eed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>I won't mention the name  They've got a lot o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>He's on top of it  And his father is a great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>Once and not so long ago three hundred thousa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>They work together to drive shoals of fish in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>Receptors in the snake's head pick up the hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>They never catch us  Because Mexico's paying ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>At the heart of all that happens here is a si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Let me tell you, what's going to happen on No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>It's hard to imagine what could have attracte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>It's actually two thousand separate reefs tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1292   I won't mention the name  They've got a lot o...      1\n",
       "883    He's on top of it  And his father is a great ...      1\n",
       "3515   Once and not so long ago three hundred thousa...      0\n",
       "2267   They work together to drive shoals of fish in...      0\n",
       "2411   Receptors in the snake's head pick up the hea...      0\n",
       "...                                                 ...    ...\n",
       "217    They never catch us  Because Mexico's paying ...      1\n",
       "2790   At the heart of all that happens here is a si...      0\n",
       "100    Let me tell you, what's going to happen on No...      1\n",
       "2091   It's hard to imagine what could have attracte...      0\n",
       "3104   It's actually two thousand separate reefs tha...      0\n",
       "\n",
       "[3518 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshuffle\n",
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea90e1f-5afe-4955-917d-4a8eb3e667f0",
   "metadata": {},
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffaa4590-f03a-4244-98d9-e3a33d033fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5cc4e4-478e-432a-b219-a151cea4b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', \"\\\"\\'\"))\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = word_tokenize(text.lower().strip())\n",
    "    text = [token.strip() for token in text if token.strip() != \"\"]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3a00d2b-8f93-405d-9ddc-e511e8c37366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c718f66f2d445dba9874ba52b88a44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d572274-fdb5-4f56-853a-c30dead54a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292    [i, wont, mention, the, name, theyve, got, a, ...\n",
       "883     [hes, on, top, of, it, and, his, father, is, a...\n",
       "3515    [once, and, not, so, long, ago, three, hundred...\n",
       "2267    [they, work, together, to, drive, shoals, of, ...\n",
       "2411    [receptors, in, the, snakes, head, pick, up, t...\n",
       "                              ...                        \n",
       "217     [they, never, catch, us, because, mexicos, pay...\n",
       "2790    [at, the, heart, of, all, that, happens, here,...\n",
       "100     [let, me, tell, you, ,, whats, going, to, happ...\n",
       "2091    [its, hard, to, imagine, what, could, have, at...\n",
       "3104    [its, actually, two, thousand, separate, reefs...\n",
       "Name: clean_text, Length: 3518, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"] # already tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4162eb86-1d17-48fe-a8ac-9531e14efee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6164"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Build Vocab\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "counts = Counter()\n",
    "for row in df[\"clean_text\"]:\n",
    "    counts.update(row)\n",
    "\n",
    "vocab2index = {\"\": 0, \"UNK\": 1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)\n",
    "\n",
    "len(vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26ee54e-b307-449e-a2e0-215b8c6325c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3518.000000\n",
       "mean       19.839113\n",
       "std         6.610641\n",
       "min         7.000000\n",
       "25%        14.000000\n",
       "50%        20.000000\n",
       "75%        25.000000\n",
       "max        45.000000\n",
       "Name: clean_text, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05070dec-5368-49c0-85aa-d242516ae7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, max_len=50):\n",
    "    encoded = np.zeros(max_len, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in text])\n",
    "    length = min(max_len, len(enc1)) # if above max len, cut the rest\n",
    "    encoded[:length] = enc1[:length]\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6507589-20a9-4837-8d6f-3d29e1360a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ENCODED_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b55a67-6ba4-4400-94ab-5a436b7944ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e20e1f6602143da96022638970a918d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"clean_text_encoded\"] = df[\"clean_text\"].progress_apply(lambda x: encode_sentence(x, vocab2index, max_len=MAX_ENCODED_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6654ce63-fbe9-4aea-b904-d197b4ab6ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>I won't mention the name  They've got a lot o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, wont, mention, the, name, theyve, got, a, ...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>He's on top of it  And his father is a great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hes, on, top, of, it, and, his, father, is, a...</td>\n",
       "      <td>[26, 27, 28, 11, 29, 30, 31, 32, 18, 9, 33, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>Once and not so long ago three hundred thousa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[once, and, not, so, long, ago, three, hundred...</td>\n",
       "      <td>[43, 30, 24, 51, 52, 42, 53, 54, 55, 56, 57, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>They work together to drive shoals of fish in...</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, work, together, to, drive, shoals, of, ...</td>\n",
       "      <td>[67, 68, 69, 70, 71, 72, 11, 73, 74, 5, 75, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>Receptors in the snake's head pick up the hea...</td>\n",
       "      <td>0</td>\n",
       "      <td>[receptors, in, the, snakes, head, pick, up, t...</td>\n",
       "      <td>[76, 77, 5, 78, 79, 80, 81, 5, 82, 83, 84, 85,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>They never catch us  Because Mexico's paying ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[they, never, catch, us, because, mexicos, pay...</td>\n",
       "      <td>[67, 287, 2001, 463, 630, 2611, 2612, 99, 5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>At the heart of all that happens here is a si...</td>\n",
       "      <td>0</td>\n",
       "      <td>[at, the, heart, of, all, that, happens, here,...</td>\n",
       "      <td>[101, 5, 1586, 11, 25, 64, 1107, 107, 18, 9, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Let me tell you, what's going to happen on No...</td>\n",
       "      <td>1</td>\n",
       "      <td>[let, me, tell, you, ,, whats, going, to, happ...</td>\n",
       "      <td>[612, 37, 186, 48, 45, 723, 98, 70, 1725, 27, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>It's hard to imagine what could have attracte...</td>\n",
       "      <td>0</td>\n",
       "      <td>[its, hard, to, imagine, what, could, have, at...</td>\n",
       "      <td>[159, 147, 70, 4022, 178, 231, 124, 4455, 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>It's actually two thousand separate reefs tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>[its, actually, two, thousand, separate, reefs...</td>\n",
       "      <td>[159, 581, 388, 55, 1234, 2929, 64, 69, 974, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3518 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "1292   I won't mention the name  They've got a lot o...      1   \n",
       "883    He's on top of it  And his father is a great ...      1   \n",
       "3515   Once and not so long ago three hundred thousa...      0   \n",
       "2267   They work together to drive shoals of fish in...      0   \n",
       "2411   Receptors in the snake's head pick up the hea...      0   \n",
       "...                                                 ...    ...   \n",
       "217    They never catch us  Because Mexico's paying ...      1   \n",
       "2790   At the heart of all that happens here is a si...      0   \n",
       "100    Let me tell you, what's going to happen on No...      1   \n",
       "2091   It's hard to imagine what could have attracte...      0   \n",
       "3104   It's actually two thousand separate reefs tha...      0   \n",
       "\n",
       "                                             clean_text  \\\n",
       "1292  [i, wont, mention, the, name, theyve, got, a, ...   \n",
       "883   [hes, on, top, of, it, and, his, father, is, a...   \n",
       "3515  [once, and, not, so, long, ago, three, hundred...   \n",
       "2267  [they, work, together, to, drive, shoals, of, ...   \n",
       "2411  [receptors, in, the, snakes, head, pick, up, t...   \n",
       "...                                                 ...   \n",
       "217   [they, never, catch, us, because, mexicos, pay...   \n",
       "2790  [at, the, heart, of, all, that, happens, here,...   \n",
       "100   [let, me, tell, you, ,, whats, going, to, happ...   \n",
       "2091  [its, hard, to, imagine, what, could, have, at...   \n",
       "3104  [its, actually, two, thousand, separate, reefs...   \n",
       "\n",
       "                                     clean_text_encoded  \n",
       "1292  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "883   [26, 27, 28, 11, 29, 30, 31, 32, 18, 9, 33, 34...  \n",
       "3515  [43, 30, 24, 51, 52, 42, 53, 54, 55, 56, 57, 5...  \n",
       "2267  [67, 68, 69, 70, 71, 72, 11, 73, 74, 5, 75, 0,...  \n",
       "2411  [76, 77, 5, 78, 79, 80, 81, 5, 82, 83, 84, 85,...  \n",
       "...                                                 ...  \n",
       "217   [67, 287, 2001, 463, 630, 2611, 2612, 99, 5, 1...  \n",
       "2790  [101, 5, 1586, 11, 25, 64, 1107, 107, 18, 9, 5...  \n",
       "100   [612, 37, 186, 48, 45, 723, 98, 70, 1725, 27, ...  \n",
       "2091  [159, 147, 70, 4022, 178, 231, 124, 4455, 29, ...  \n",
       "3104  [159, 581, 388, 55, 1234, 2929, 64, 69, 974, 9...  \n",
       "\n",
       "[3518 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c211a-72fb-4858-9ff6-16d169fa01d9",
   "metadata": {},
   "source": [
    "# DataLoader for Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74385801-b159-4706-8eed-cc9497ceade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69582f25-4c82-4735-ab65-1f0e4a4b44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.mps.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4a2783-e89e-446a-95e5-118d35ea574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df[\"clean_text_encoded\"], df[\"label\"], test_size=0.2, random_state=3407, stratify=df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4508004-11f0-4025-9975-1cfa4992d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStyleDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = np.vstack(data)\n",
    "        self.labels = torch.tensor(labels.to_numpy(), dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ab73cf2-e00c-4505-87be-9a4965a42ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    377\n",
       "0    327\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ed60e3-7d6e-4b1f-b25c-be7711514500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextStyleDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "val_ds = TextStyleDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c96b638-7df5-4b1c-8eb0-0150582fca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50])\n",
      "tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(x[0].shape)\n",
    "    print(x[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fb77f-8d54-4770-82b8-5e54912e3f4e",
   "metadata": {},
   "source": [
    "# ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ded5c51-d710-4966-9ae6-f9fcc09d39b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe7e236-0601-4a1b-9ae8-c33081664971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f881170d-10e1-4718-a368-b8230561b329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6164"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab2index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "195a83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../models/vocab2index_style_classification.json\", 'w') as f:\n",
    "    json.dump(vocab2index, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6ddf9d95-4992-43b8-b5fb-54a8c36a6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, output_size):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=128)\n",
    "\n",
    "        self.linear_size = input_size * 128\n",
    "        self.linear1 = nn.Linear(self.linear_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.linear3 = nn.Linear(64, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # we assume the inputs already in embedding dimension\n",
    "        output = self.embedding(inputs).view(-1, self.linear_size)\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.dropout1(output)\n",
    "        output = self.linear3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b5df3ad6-1d3e-4e5f-8daa-6b6335009412",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = SimpleLinearModel(vocab_size=vocab_size, input_size=MAX_ENCODED_LEN, output_size=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e3cbbfbd-e781-4dc3-bf2a-2939541f8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "78a2ddc4-f0ad-44c4-8d09-642c10785ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, train_loader, val_loader, epochs=EPOCHS):\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):  # Loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item() \n",
    "\n",
    "            predicted = torch.round(F.sigmoid(outputs))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        # get train loss and accuracy\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "    \n",
    "        # get test loss and accuracy\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data in val_loader:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.round(F.sigmoid(outputs))\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss: {train_loss:.4f}; train_accuracy: {train_accuracy:.4f}; val_loss: {val_loss:.4f}; val_accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"train_accuracy\": train_accuracies,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a4722e4b-16a0-456c-864e-11691b07af99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 0.0147; train_accuracy: 0.7854; val_loss: 0.3179; val_accuracy: 0.8565\n",
      "Epoch 1: train_loss: 0.0063; train_accuracy: 0.9204; val_loss: 0.2351; val_accuracy: 0.9077\n",
      "Epoch 2: train_loss: 0.0022; train_accuracy: 0.9751; val_loss: 0.2006; val_accuracy: 0.9304\n",
      "Epoch 3: train_loss: 0.0009; train_accuracy: 0.9922; val_loss: 0.1468; val_accuracy: 0.9531\n",
      "Epoch 4: train_loss: 0.0002; train_accuracy: 0.9982; val_loss: 0.2341; val_accuracy: 0.9403\n",
      "Epoch 5: train_loss: 0.0002; train_accuracy: 0.9986; val_loss: 0.2424; val_accuracy: 0.9361\n",
      "Epoch 6: train_loss: 0.0002; train_accuracy: 0.9975; val_loss: 0.1743; val_accuracy: 0.9631\n",
      "Epoch 7: train_loss: 0.0000; train_accuracy: 1.0000; val_loss: 0.1857; val_accuracy: 0.9645\n",
      "Epoch 8: train_loss: 0.0000; train_accuracy: 1.0000; val_loss: 0.1975; val_accuracy: 0.9645\n",
      "Epoch 9: train_loss: 0.0000; train_accuracy: 1.0000; val_loss: 0.1953; val_accuracy: 0.9659\n"
     ]
    }
   ],
   "source": [
    "linear_model_result = fit(linear_model, criterion, optimizer, train_loader, val_loader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0fa64651-c845-4257-9b9f-c1d0276baa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        \n",
    "        self.bilstm = nn.LSTM(128, 128, bidirectional=True, batch_first=True, dropout=0.1, num_layers=2)\n",
    "        self.linear1 = nn.Linear(128 * 2, 64)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding(x)\n",
    "        output, _ = self.bilstm(output)\n",
    "\n",
    "        output = output[:, -1, :]  # Get the output of the last time step\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear2(output)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e0f8129c-b54c-4813-947d-4187b1ca70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = RNNModel(vocab_size=vocab_size, output_size=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7ea64b5b-c596-4216-9a70-6269f165bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 0.0216; train_accuracy: 0.5327; val_loss: 0.6749; val_accuracy: 0.5355\n",
      "Epoch 1: train_loss: 0.0142; train_accuracy: 0.8262; val_loss: 0.2555; val_accuracy: 0.9119\n",
      "Epoch 2: train_loss: 0.0036; train_accuracy: 0.9648; val_loss: 0.1323; val_accuracy: 0.9574\n",
      "Epoch 3: train_loss: 0.0019; train_accuracy: 0.9797; val_loss: 0.1112; val_accuracy: 0.9702\n",
      "Epoch 4: train_loss: 0.0005; train_accuracy: 0.9957; val_loss: 0.1304; val_accuracy: 0.9673\n",
      "Epoch 5: train_loss: 0.0006; train_accuracy: 0.9929; val_loss: 0.1076; val_accuracy: 0.9716\n",
      "Epoch 6: train_loss: 0.0003; train_accuracy: 0.9979; val_loss: 0.1099; val_accuracy: 0.9716\n",
      "Epoch 7: train_loss: 0.0001; train_accuracy: 0.9993; val_loss: 0.1508; val_accuracy: 0.9688\n",
      "Epoch 8: train_loss: 0.0000; train_accuracy: 1.0000; val_loss: 0.1705; val_accuracy: 0.9716\n",
      "Epoch 9: train_loss: 0.0000; train_accuracy: 1.0000; val_loss: 0.1860; val_accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "rnn_model_result = fit(rnn_model, criterion, optimizer, train_loader, val_loader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335cb6-079b-4b0a-9d64-fa8d78b9ea18",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "920a42c2-b89e-4c65-b0e6-219e10ee3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_map = {\n",
    "    0: \"david\",\n",
    "    1: \"trump\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2a0c5ac4-0b51-4b4a-9389-a39f7abbc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    text = clean_text(text)\n",
    "    encoded_text = torch.tensor(encode_sentence(text, vocab2index, MAX_ENCODED_LEN)).unsqueeze(0).to(device)\n",
    "    style_label = torch.tensor([0], dtype=torch.long).repeat(encoded_text.shape[0]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(encoded_text)\n",
    "        predicted_proba = F.sigmoid(outputs)\n",
    "        predicted = torch.round(predicted_proba)\n",
    "        predicted_style = style_map[int(predicted.data[0][0].cpu().numpy())]\n",
    "\n",
    "    return predicted_proba, predicted, predicted_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3e666444-ab20-4439-a5a1-0bc680ec2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000]], device='mps:0'), tensor([[1.]], device='mps:0'), 'trump')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(linear_model, \"You are fake news, believe me, nobody knows fake news better than I do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8d9198c3-4c0f-4139-ac9b-36b5c286cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8561]], device='mps:0'), tensor([[1.]], device='mps:0'), 'trump')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(linear_model, \"Observe this fake news. In the rich tapestry of media, there are some who, regrettably, disseminate misinformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1c4f751c-c253-45ea-b0dc-6350ed212a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9968]], device='mps:0'), tensor([[1.]], device='mps:0'), 'trump')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(rnn_model, \"You are fake news, believe me, nobody knows fake news better than I do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "52bda2c9-e7d3-447f-8415-fd29dca96dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0459]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(rnn_model, \"Observe this fake news. In the rich tapestry of media, there are some who, regrettably, disseminate misinformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e29ca805-27ce-4d10-997f-760753620c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), \"../models/style_classification_linear.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a32ed01c-7009-4548-84cd-5c1025072e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn_model.state_dict(), \"../models/style_classification_rnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9303ec5b-27a2-4b8b-9753-297f42f1ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/style/vocab2index.json\", 'w') as f:\n",
    "    json.dump(vocab2index, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "623b5ef6-de6d-4ecd-8541-f7530a3d757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[9.7496e-08]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')\n",
      "(tensor([[4.1616e-09]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')\n",
      "(tensor([[3.4351e-09]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')\n"
     ]
    }
   ],
   "source": [
    "print(predict(linear_model, \"i i the the the the the\"))\n",
    "print(predict(linear_model, \"to to to to to to to to to\"))\n",
    "print(predict(linear_model, \"the to to to to to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cd50c68b-e626-41b1-85f1-4cda86d0ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.9891]], device='mps:0'), tensor([[1.]], device='mps:0'), 'trump')\n",
      "(tensor([[0.0457]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')\n",
      "(tensor([[0.0457]], device='mps:0'), tensor([[0.]], device='mps:0'), 'david')\n"
     ]
    }
   ],
   "source": [
    "print(predict(rnn_model, \"i i the the the the the\"))\n",
    "print(predict(rnn_model, \"to to to to to to to to to\"))\n",
    "print(predict(rnn_model, \"the to to to to to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7240e-241e-4157-a61e-8b5fd9e378c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
